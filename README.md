# Ishan Mishra  
### Machine Learning Engineer | Designing AI Systems for the Real World

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?logo=linkedin)](https://www.linkedin.com/in/ihrm-ishan/)
![Profile Views](https://komarev.com/ghpvc/?username=ihrm-ishan&color=blue)

---

## ğŸ§  How I Think About AI

Most ML engineers focus on **models**.  
I focus on **decisions, systems, and constraints**.

> A good model in a bad system fails in production.

I design AI systems where **models are one component**, not the entire solution.

---

## ğŸ” What I Build

- End-to-end **ML & LLM systems**
- **RAG pipelines** with evaluation and guardrails
- Cloud-deployed AI services (GCP)
- Decision-support tools, not just predictions
- Responsible AI with governance and privacy awareness

---

## ğŸ—ï¸ Architecture Sketches (System-Level View)
User
â”‚
â–¼
Web / API Gateway
â”‚
â–¼
Request Router
â”‚
â”œâ”€â”€â–º Embedding Model
â”‚ â”‚
â”‚ â–¼
â”‚ Vector Database
â”‚ â”‚
â”‚ â–¼
â”‚ Context Retrieval
â”‚
â””â”€â”€â–º Prompt Composer
â”‚
â–¼
LLM (LoRA / Fine-tuned)
â”‚
â–¼
Response Validator
â”‚
â–¼
User


**Design priorities:**  
Low latency â€¢ Cost control â€¢ Explainability â€¢ Replaceable components

---

### 2ï¸âƒ£ ML System Lifecycle I Optimize For

Problem â†’ Data â†’ Features â†’ Model â†’ API â†’ Deployment â†’ Monitoring â†’ Feedback


Most failures occur **after training** â€” thatâ€™s where I invest most effort.

---

## ğŸ“Œ Pinned Project (Primary System)

### ğŸ”¹ AI-Powered Decision Support System (LLM + RAG)

**What it is**  
A cloud-hosted AI assistant that retrieves domain-specific knowledge and generates grounded, explainable responses.

**Why it matters**  
Moves beyond chatbot demos into **usable enterprise AI systems**.

### System Highlights
- Retrieval-Augmented Generation (reduced hallucinations)
- LoRA-based fine-tuning for domain adaptation
- Modular architecture (model-agnostic design)
- GCP-based deployment with scalable inference

### Measured Impact
- â±ï¸ **Latency:** â†“ ~35% (prompt optimization + caching)
- ğŸ’° **Inference Cost:** â†“ ~30% (LoRA + batching)
- ğŸ¯ **Response Accuracy:** â†‘ ~20% (retrieval grounding)
- âŒ **Hallucinations:** Significantly reduced via context constraints

> This is the system pinned on my GitHub â€” it reflects how I engineer AI.

---

## âš™ï¸ Technical Stack (Used in Practice)

**Languages**  
Python, SQL

**Machine Learning & AI**  
Classical ML, Deep Learning, Transformers  
Large Language Models, RAG, Prompt Engineering  
Hugging Face, PEFT, LoRA

**Data & Analytics**  
EDA, feature engineering  
Tableau, Power BI

**Cloud & Tools**  
Google Cloud (Firebase, AppSheet, Flutter, Looker)  
IBM Cloud  
Git, GitHub

---

## âŒ A Failure I Learned From

### â€œThe model worked. Production didnâ€™t.â€

I once built a high-accuracy ML model that failed in production because:
- Data distribution shifted
- Inference latency wasnâ€™t considered
- No monitoring or feedback loop existed

**What this taught me**
- Design monitoring **before** training
- Validate latency and cost early
- Treat deployment as part of ML, not an afterthought

That failure shaped my engineering mindset more than any success.

---

## ğŸ† Selected Credentials

- **Tata Insights & Quants** â€” GenAI Powered Data Analytics  
- **Deloitte Australia** â€” Data Analytics  
- **Infosys Springboard** â€” Generative AI Landscape  
- **IBM** â€” Data Science & Machine Learning Foundations  
- **Google Cloud Skills Boost** â€” Firebase, AppSheet, Flutter, Looker  

---

## ğŸ§­ Engineering Principles

- Simple systems beat complex models
- Data quality > algorithm complexity
- If it canâ€™t be deployed, itâ€™s not done
- Ethics and governance are engineering problems

---

## ğŸŒ Letâ€™s Connect

If youâ€™re building:
- Production ML or GenAI systems
- Cloud-native AI products
- Decision-support platforms

ğŸ“© LinkedIn: https://www.linkedin.com/in/ihrm-ishan/

---

<p align="center">
<b>Engineering AI that works beyond notebooks.</b>
</p>


### 1ï¸âƒ£ LLM + RAG Production Architecture

